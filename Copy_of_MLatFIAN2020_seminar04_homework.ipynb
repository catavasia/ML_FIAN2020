{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MLatFIAN2020_seminar04_homework.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/catavasia/ML_FIAN2020/blob/master/Copy_of_MLatFIAN2020_seminar04_homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoRenk6WqY4R"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsk47s-JzFMY"
      },
      "source": [
        "## Task 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_72sYvZSzO4B"
      },
      "source": [
        "(Titanic data again)\n",
        "\n",
        "Build a model with `sklearn`'s `LogisticRegression` or `SVC` to get the accuracy of at least 0.81 on the test set. Can you get higher? 0.84?\n",
        "\n",
        "Some (optional) suggestions:\n",
        "- Add new features (e.g. missing value indicator columns)\n",
        "- Fill missing values\n",
        "- Encode categorical features (e.g. one-hot encoding)\n",
        "- Scale the features (e.g. with standard or robust scaler)\n",
        "- Think of other ways of preprocessing the features (e.g. `Fare` $\\to$ `log(Fare)`)\n",
        "- Try adding polynomial features\n",
        "- use `sklearn.model_selection.GridSearchCV` to search for the best hyperparameters (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CWHxPY62I-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0abd39be-b973-49c2-c75d-47613ea465d8"
      },
      "source": [
        "!wget https://github.com/HSE-LAMBDA/MLDM-2020/raw/master/day-01/train.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-30 15:31:24--  https://github.com/HSE-LAMBDA/MLDM-2020/raw/master/day-01/train.csv\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/HSE-LAMBDA/MLDM-2020/master/day-01/train.csv [following]\n",
            "--2020-11-30 15:31:25--  https://raw.githubusercontent.com/HSE-LAMBDA/MLDM-2020/master/day-01/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60302 (59K) [text/plain]\n",
            "Saving to: ‘train.csv.1’\n",
            "\n",
            "train.csv.1         100%[===================>]  58.89K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2020-11-30 15:31:26 (7.19 MB/s) - ‘train.csv.1’ saved [60302/60302]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G36oVo3RJXVc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1351b7f2-064a-4d20-8ba3-0f3e1d8cd133"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"train.csv\", index_col='PassengerId')\n",
        "data.head()\n",
        "nan = data.Embarked.isna()\n",
        "for i in nan:\n",
        "  if i !=False:\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDHw3sHgJXVj"
      },
      "source": [
        "#### About the data\n",
        "Here's some of the columns\n",
        "* Name - a string with person's full name\n",
        "* Survived - 1 if a person survived the shipwreck, 0 otherwise.\n",
        "* Pclass - passenger class. Pclass == 3 is cheap'n'cheerful, Pclass == 1 is for moneybags.\n",
        "* Sex - a person's gender\n",
        "* Age - age in years, if available - the only missing parameter\n",
        "* SibSp - number of siblings on a ship\n",
        "* Parch - number of parents on a ship\n",
        "* Fare - ticket cost\n",
        "* Embarked - port where the passenger embarked\n",
        " * C = Cherbourg; Q = Queenstown; S = Southampton"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhb45c3NzHAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c52f92-b8d4-4ec1-ddee-f9006b27d7e3"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, PolynomialFeatures, OneHotEncoder, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def feature_selection_and_preprocessing(dataset):\n",
        "  # <YOUR CODE>\n",
        "  # E.g.:\n",
        "  features = dataset[[\"Fare\", \"Parch\", \"Pclass\",'Sex']].copy()\n",
        "  features[\"Age\"] = dataset.Age.fillna(dataset.Age.median())\n",
        "  #td.Embarked.fillna(td.Embarked.mode()[0], inplace = True)\n",
        "  features['Embarked'] = dataset.Embarked.fillna(dataset.Embarked.mode()[0])\n",
        "  #print(features.keys)\n",
        "  return features\n",
        "\n",
        "#[0.001,.009,0.01,.09,1,5,10,25, 50]\n",
        "\n",
        "a = np.linspace(0.5, 15, 30)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "clf = SVC()\n",
        "grid_values = {'kernel':['rbf', 'linear'], 'C':a}\n",
        "grid_clf_acc = GridSearchCV(clf, param_grid = grid_values)\n",
        "model = make_pipeline(\n",
        "    # <YOUR CODE>\n",
        "    # E.g.\n",
        "    make_column_transformer(\n",
        "        (OneHotEncoder(sparse=False), ['Embarked']),\n",
        "        (OneHotEncoder(sparse=False), ['Sex']),\n",
        "        remainder='passthrough'\n",
        "    ), \n",
        "    RobustScaler(),\n",
        "   grid_clf_acc\n",
        ")\n",
        "\n",
        "\n",
        "# Validation code (do not touch)\n",
        "data = pd.read_csv(\"train.csv\", index_col='PassengerId')\n",
        "data_train, data_test = train_test_split(data, test_size=90, random_state=42)\n",
        "\n",
        "model.fit(\n",
        "    feature_selection_and_preprocessing(\n",
        "        data_train.drop('Survived', axis=1)\n",
        "    ),\n",
        "    data_train['Survived']\n",
        ")\n",
        "\n",
        "train_predictions = model.predict(\n",
        "    feature_selection_and_preprocessing(\n",
        "        data_train.drop('Survived', axis=1)\n",
        "    )\n",
        ")\n",
        "\n",
        "test_predictions = model.predict(\n",
        "    feature_selection_and_preprocessing(\n",
        "        data_test.drop('Survived', axis=1)\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"Train accuracy:\", accuracy_score(\n",
        "    data_train['Survived'],\n",
        "    train_predictions\n",
        "))\n",
        "print(\"Test accuracy:\", accuracy_score(\n",
        "    data_test['Survived'],\n",
        "    test_predictions\n",
        "))"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.8439450686641697\n",
            "Test accuracy: 0.8444444444444444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBitd-MKSwdc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}